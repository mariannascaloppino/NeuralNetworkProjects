{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Approach based on Convolutional Neural Networks for image classification. To this end, we will use the Keras library, which provides a set of functions that facilitate various operations such as data preparation, the definition of the neural network architecture, training, and performance analysis.\n",
        "\n",
        "As a first example of classification, we will tackle the problem of recognizing handwritten digits from 0 to 9 using the MNIST dataset. This dataset consists of a total of 70,000 grayscale images, each with a resolution of 28 × 28 pixels."
      ],
      "metadata": {
        "id": "a-AQCHxXZMYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EV32xVfcaf-Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAgMTHtdVyeE"
      },
      "outputs": [],
      "source": [
        "#caricamento e preparazione dei dati\n",
        "%reset -f\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "#carica i dati MINST\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "id = 300\n",
        "img = x_test[id,:,:]\n",
        "y = y_test[id]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(img, clim=[0,255], cmap='gray')\n",
        "plt.title(y)\n",
        "plt.show()\n",
        "\n",
        "x_valid = x_train[::12]\n",
        "y_valid = y_train[::12]\n",
        "x_train = np.delete(x_train,np.arange(0,60000,12),0) #sul primo asse scorro le immagini quindi sulla dim 0\n",
        "y_train = np.delete(y_train,np.arange(0,60000,12),0) #sul primo asse scorro le immagini quindi sulla dim 0\n",
        "%whos\n",
        "img_rows = 28 ; img_cols = 28 ; num_classes = 10\n",
        "\n",
        "x_test = np.reshape(x_test, (-1, img_rows, img_cols,1))\n",
        "x_train = np.reshape(x_train, (-1, img_rows, img_cols,1))\n",
        "x_valid = np.reshape(x_valid, (-1, img_rows, img_cols,1))\n",
        "x_test = np.float32(x_test) / 255\n",
        "x_train = np.float32(x_train) / 255\n",
        "x_valid = np.float32(x_valid) / 255 #float32 va piu veloci delle 64 sulle gpu\n",
        "#per convertire le etichette da formato sparso a fromato one hot: dopo questa conversione le etichette non saranno piu vettori ma matrici.\n",
        "#le  colonne sono pari al numero di classi\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_tets = to_categorical(y_test, num_classes ) #è pari al numeor di classi\n",
        "y_train = to_categorical(y_train, num_classes )\n",
        "y_valid = to_categorical(y_valid, num_classes )\n",
        "\n",
        "y_test[id] #vettore lungo 10 pari al numeoro di classi\n",
        "\n",
        "#Creiamo rete LENET\"\"\"\n",
        "\n",
        "from tensorflow.keras import layers #ci sono tuttti i livelli prefatti: convoluzionali\n",
        "lenet = keras.models.Sequential() # crea rete senza livelli completamente vuota\n",
        "layer1 = layers.Conv2D(6,(5,5), padding='same', activation='relu',input_shape=(img_rows,img_cols,1))#primo parametro: numero di filtri, dimensione del filtro, operazioni opzionali: considera 0 al di fuori dell imagine\n",
        "#imput shape va indicato solo nel primo livello\n",
        "#se lavoriamo su audio possiamo mettere conv 1d, dimensione filtro 2x2 parametri opzionali per  bordi , funzione id attivazione\n",
        "#input con un certo numero di righe colonne e canali\n",
        "\n",
        "lenet.add(layer1) #aggiungo layer1 a lenet\n",
        "\n",
        "layer2 = layers.MaxPooling2D((2,2))\n",
        "lenet.add(layer2)\n",
        "\n",
        "layer3 = layers.Conv2D(16, (5,5), padding='valid', activation='relu')\n",
        "lenet.add(layer3)\n",
        "\n",
        "layer4 = layers.MaxPooling2D((2,2))\n",
        "lenet.add(layer4)\n",
        "#bisogna applicare una trasformazione dati, quindi mettiamo un layer fittizio che fa un operazione di fratel:\n",
        "#prende una matrice e la fa diventare un vettore\"\"\"\n",
        "layer5 =layers.Dense(120, activation='relu') #numero di neuroni in uscita e funzzione di attivazione\n",
        "lenet.add(layer5)\n",
        "\n",
        "layer6 = layers.Dense(84, activation='relu')\n",
        "lenet.add(layer6)\n",
        "\n",
        "layer7 = layers.Dense(10, activation='softmax')\n",
        "lenet.add(layer7)\n",
        "#per avere info sulla rete e i suoi parametri\"\"\"\n",
        "lenet.summary() #tabella riassuntiva\n",
        "#definiti i dati e la rete ora bisogna definire la funzione di loss e la tecnica di ottimizazzione\"\"\"\n",
        "\n",
        "#addestramento\n",
        "lenet.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(learning_rate = 0.01),\n",
        "              metrics = [keras.metrics.CategoricalAccuracy(),]) #categorical perchè le etichette le abbioamo invertite in formato one hot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lTpAdx5WaZsM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3c1089b-0b7e-4c28-ed0f-f73c5d2cd3ef",
        "id": "XQA9UnjYaaob"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable   Type       Data/Info\n",
            "-------------------------------\n",
            "id         int        300\n",
            "img        ndarray    28x28: 784 elems, type `uint8`, 784 bytes\n",
            "keras      module     <module 'keras.api._v2.ke<...>i/_v2/keras/__init__.py'>\n",
            "mnist      module     <module 'keras.api._v2.ke<...>asets/mnist/__init__.py'>\n",
            "np         module     <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
            "plt        module     <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
            "x_test     ndarray    10000x28x28: 7840000 elems, type `uint8`, 7840000 bytes (7.476806640625 Mb)\n",
            "x_train    ndarray    55000x28x28: 43120000 elems, type `uint8`, 43120000 bytes (41.1224365234375 Mb)\n",
            "x_valid    ndarray    5000x28x28: 3920000 elems, type `uint8`, 3920000 bytes (3.7384033203125 Mb)\n",
            "y          uint8      4\n",
            "y_test     ndarray    10000: 10000 elems, type `uint8`, 10000 bytes\n",
            "y_train    ndarray    55000: 55000 elems, type `uint8`, 55000 bytes\n",
            "y_valid    ndarray    5000: 5000 elems, type `uint8`, 5000 bytes\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5, 5, 120)         2040      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5, 5, 84)          10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5, 5, 10)          850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,626\n",
            "Trainable params: 15,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#TESTIAMO LA RETE SU UN'IMMAGINE\n",
        "%reset -f\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "#carica i dati MINST\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "id = 300\n",
        "img = x_test[id,:,:]\n",
        "y = y_test[id]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(img, clim=[0,255], cmap='gray')\n",
        "plt.title(y)\n",
        "plt.show()\n",
        "\n",
        "x_valid = x_train[::12]\n",
        "y_valid = y_train[::12]\n",
        "x_train = np.delete(x_train,np.arange(0,60000,12),0) #sul primo asse scorro le immagini quindi sulla dim 0\n",
        "y_train = np.delete(y_train,np.arange(0,60000,12),0) #sul primo asse scorro le immagini quindi sulla dim 0\n",
        "%whos\n",
        "img_rows = 28 ; img_cols = 28 ; num_classes = 10\n",
        "\n",
        "x_test = np.reshape(x_test, (-1, img_rows, img_cols,1))\n",
        "x_train = np.reshape(x_train, (-1, img_rows, img_cols,1))\n",
        "x_valid = np.reshape(x_valid, (-1, img_rows, img_cols,1))\n",
        "x_test = np.float32(x_test) / 255\n",
        "x_train = np.float32(x_train) / 255\n",
        "x_valid = np.float32(x_valid) / 255 #float32 va piu veloci delle 64 sulle gpu\n",
        "#per convertire le etichette da formato sparso a fromato one hot: dopo questa conversione le etichette non saranno piu vettori ma matrici . le  colonne sono pari al numero di classi e le righe\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_tets = to_categorical(y_test, num_classes )#è pari al numeor di classi\n",
        "y_train = to_categorical(y_train, num_classes )\n",
        "y_valid = to_categorical(y_valid, num_classes )\n",
        "\n",
        "y_test[id] #vettore lungo 10 pari al numeoro di classi\n",
        "\n",
        "#Creiamo rete lenet\"\"\"\n",
        "from tensorflow.keras import layers #ci sono tuttti i livelli prefatti: convoluzionali\n",
        "lenet = keras.models.Sequential() # crea rete senza livelli completamente vuota\n",
        "layer1 = layers.Conv2D(6,(5,5), padding='same', activation='relu',input_shape=(img_rows,img_cols,1))#primo parametro: numero di filtri, dimensione del filtro, operazioni opzionali: considera 0 al di fuori dell imagine\n",
        "#imput shape va indicato solo nel primo livello\n",
        "#se lavoriamo su audio possiamo mettere conv 1d, dimensione filtro 2x2 parametri opzionali per  bordi , funzione id attivazione\n",
        "#input con un certo numero di righe colonne e canali\n",
        "\n",
        "lenet.add(layer1) #aggiungo layer1 a lenet\n",
        "\n",
        "layer2 = layers.MaxPooling2D((2,2))#bocchetto su cui fare il massismo\n",
        "lenet.add(layer2)\n",
        "\n",
        "layer3 = layers.Conv2D(16, (5,5), padding='valid', activation='relu')\n",
        "lenet.add(layer3)\n",
        "\n",
        "layer4 = layers.MaxPooling2D((2,2))\n",
        "lenet.add(layer4)\n",
        "#bisogna applicare una trasformazione dati, quindi mettiamo un layer fittizio che fa un operazione di fratel:\n",
        "#prende una matrice e la fa diventare un vettore\"\"\"\n",
        "layer5 =layers.Dense(120, activation='relu') #numero di neuroni in uscita e funzzione di attivazione\n",
        "lenet.add(layer5)\n",
        "\n",
        "layer6 = layers.Dense(84, activation='relu')\n",
        "lenet.add(layer6)\n",
        "\n",
        "layer7 = layers.Dense(10, activation='softmax')\n",
        "lenet.add(layer7)\n",
        "#per avere info sulla rete e i suoi parametri\"\"\"\n",
        "lenet.summary() #tabella riassuntiva\n",
        "#definiti i dati e la rete ora bisogna definire la funzione di loss e la tecnica di ottimizazzione\"\"\"\n",
        "lenet.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(learning_rate = 0.01),\n",
        "              metrics = [keras.metrics.CategoricalAccuracy(),]) #categorical perchè le etichette le abbioamo invertite in formato one hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "lenet.fit(x_train, y_train, batch_size=200, epochs=10, validation_data=(x_valid, y_valid))\n",
        "\n",
        "#analisi delle prestazioni\n",
        "lenet.evaluate(x_test, y_test, batch_size=200)\n",
        "\n",
        "y_pred = lenet.predict(x_test, batch_size=200) #uscita della rete\n",
        "y_pred = np.argmax(y_pred, 1)  #voglio sapere a che classe assegnare immagine in ingresso e non la probabilità come sopra\n",
        "y_true = np.argmax(y_test,1)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_true, y_pred) #matrice di confusione\n",
        "#se voglio vedere predizione su una singola immagine\"\"\"\n",
        "id =100\n",
        "img = x_test[id,:,:,:]\n",
        "vero = np.argmax(y_test[id])\n",
        "img= np.reshape(img, (1,28,28,1))\n",
        "predizione = lenet.predict(img) #predict lavora su piu immagini alla volta percio dobbiamo fare prima il reshape\n",
        "\n",
        "plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img[0,:,:,0], clim=[0,1], cmap='gray')\n",
        "plt.title(vero)\n",
        "plt.subplot(1,2,2)\n",
        "plt.bar(np.arange(0,10), predizione[0,:])\n",
        "plt.xticks(np.arange(0,10)) # per visualizzare meglio la figura\n",
        "plt.show()\n",
        "lenet.predict() #lavora su 4 immagini alla volta\n",
        "#!nvidia-smi #da potenza e memoria occupata.."
      ],
      "metadata": {
        "id": "x1ds5O9039Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ErTYlCKdk3w8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}